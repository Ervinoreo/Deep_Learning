{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNc2cRnJcq79Ch/+qrVtQod",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ervinoreo/Deep_Learning/blob/main/cnn(cifar10).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U7YJZIdbyBjE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as py\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "num_epochs = 100\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "train_dataset = torchvision.datasets.CIFAR10(root = 'data', train = True, download = True, transform = transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root = 'data', train = False, download = True, transform = transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgT1NLkbD8IB",
        "outputId": "77248363-50e9-40e7-dd47-9c8f2eb7c5bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 75734756.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,6,5)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn.Conv2d(6,16,5)\n",
        "    self.fc1 = nn.Linear(16*5*5,120)\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1,16*5*5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "n_total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i + 1) % 2000 == 0:\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_step}], Loss: {loss.item():.4f}')\n",
        "\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  n_class_correct = [0 for i in range(10)]\n",
        "  n_class_samples = [0 for i in range(10)]\n",
        "\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    n_samples += labels.size(0)\n",
        "    n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      label = labels[i]\n",
        "      pred = predicted[i]\n",
        "      if (label == pred):\n",
        "        n_class_correct[label] += 1\n",
        "      n_class_samples[label] += 1\n",
        "\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'Accuracy of the network {acc} %')\n",
        "\n",
        "  for i in range(10):\n",
        "    acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "    print(f'Accuracy of {classes[i]}: {acc}%')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdXNOwghSQ07",
        "outputId": "956ccd36-35c0-4d88-c083-292b9650eb94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Step [2000/12500], Loss: 2.3176\n",
            "Epoch [1/100], Step [4000/12500], Loss: 2.3038\n",
            "Epoch [1/100], Step [6000/12500], Loss: 2.2818\n",
            "Epoch [1/100], Step [8000/12500], Loss: 2.2952\n",
            "Epoch [1/100], Step [10000/12500], Loss: 2.2859\n",
            "Epoch [1/100], Step [12000/12500], Loss: 2.3981\n",
            "Epoch [2/100], Step [2000/12500], Loss: 2.6761\n",
            "Epoch [2/100], Step [4000/12500], Loss: 1.9823\n",
            "Epoch [2/100], Step [6000/12500], Loss: 2.2402\n",
            "Epoch [2/100], Step [8000/12500], Loss: 1.5190\n",
            "Epoch [2/100], Step [10000/12500], Loss: 1.9361\n",
            "Epoch [2/100], Step [12000/12500], Loss: 1.0975\n",
            "Epoch [3/100], Step [2000/12500], Loss: 1.1448\n",
            "Epoch [3/100], Step [4000/12500], Loss: 1.7694\n",
            "Epoch [3/100], Step [6000/12500], Loss: 2.1333\n",
            "Epoch [3/100], Step [8000/12500], Loss: 1.4434\n",
            "Epoch [3/100], Step [10000/12500], Loss: 2.4362\n",
            "Epoch [3/100], Step [12000/12500], Loss: 1.4172\n",
            "Epoch [4/100], Step [2000/12500], Loss: 2.0119\n",
            "Epoch [4/100], Step [4000/12500], Loss: 1.8299\n",
            "Epoch [4/100], Step [6000/12500], Loss: 0.6452\n",
            "Epoch [4/100], Step [8000/12500], Loss: 1.0656\n",
            "Epoch [4/100], Step [10000/12500], Loss: 1.8444\n",
            "Epoch [4/100], Step [12000/12500], Loss: 1.6194\n",
            "Epoch [5/100], Step [2000/12500], Loss: 0.4737\n",
            "Epoch [5/100], Step [4000/12500], Loss: 1.1723\n",
            "Epoch [5/100], Step [6000/12500], Loss: 1.8892\n",
            "Epoch [5/100], Step [8000/12500], Loss: 1.3675\n",
            "Epoch [5/100], Step [10000/12500], Loss: 1.7113\n",
            "Epoch [5/100], Step [12000/12500], Loss: 0.8968\n",
            "Epoch [6/100], Step [2000/12500], Loss: 1.7040\n",
            "Epoch [6/100], Step [4000/12500], Loss: 1.2984\n",
            "Epoch [6/100], Step [6000/12500], Loss: 1.2500\n",
            "Epoch [6/100], Step [8000/12500], Loss: 1.9112\n",
            "Epoch [6/100], Step [10000/12500], Loss: 1.4678\n",
            "Epoch [6/100], Step [12000/12500], Loss: 0.7905\n",
            "Epoch [7/100], Step [2000/12500], Loss: 2.0667\n",
            "Epoch [7/100], Step [4000/12500], Loss: 1.3167\n",
            "Epoch [7/100], Step [6000/12500], Loss: 1.7067\n",
            "Epoch [7/100], Step [8000/12500], Loss: 0.5404\n",
            "Epoch [7/100], Step [10000/12500], Loss: 0.9478\n",
            "Epoch [7/100], Step [12000/12500], Loss: 0.5955\n",
            "Epoch [8/100], Step [2000/12500], Loss: 0.4194\n",
            "Epoch [8/100], Step [4000/12500], Loss: 0.5748\n",
            "Epoch [8/100], Step [6000/12500], Loss: 2.1841\n",
            "Epoch [8/100], Step [8000/12500], Loss: 1.2166\n",
            "Epoch [8/100], Step [10000/12500], Loss: 2.0137\n",
            "Epoch [8/100], Step [12000/12500], Loss: 1.2627\n",
            "Epoch [9/100], Step [2000/12500], Loss: 0.9410\n",
            "Epoch [9/100], Step [4000/12500], Loss: 1.0531\n",
            "Epoch [9/100], Step [6000/12500], Loss: 0.8026\n",
            "Epoch [9/100], Step [8000/12500], Loss: 1.1818\n",
            "Epoch [9/100], Step [10000/12500], Loss: 1.6176\n",
            "Epoch [9/100], Step [12000/12500], Loss: 1.7942\n",
            "Epoch [10/100], Step [2000/12500], Loss: 0.4995\n",
            "Epoch [10/100], Step [4000/12500], Loss: 1.2021\n",
            "Epoch [10/100], Step [6000/12500], Loss: 1.2667\n",
            "Epoch [10/100], Step [8000/12500], Loss: 0.8986\n",
            "Epoch [10/100], Step [10000/12500], Loss: 0.5411\n",
            "Epoch [10/100], Step [12000/12500], Loss: 0.6745\n",
            "Epoch [11/100], Step [2000/12500], Loss: 1.4295\n",
            "Epoch [11/100], Step [4000/12500], Loss: 0.4756\n",
            "Epoch [11/100], Step [6000/12500], Loss: 2.0361\n",
            "Epoch [11/100], Step [8000/12500], Loss: 0.3220\n",
            "Epoch [11/100], Step [10000/12500], Loss: 1.5783\n",
            "Epoch [11/100], Step [12000/12500], Loss: 1.2949\n",
            "Epoch [12/100], Step [2000/12500], Loss: 1.1127\n",
            "Epoch [12/100], Step [4000/12500], Loss: 0.5861\n",
            "Epoch [12/100], Step [6000/12500], Loss: 0.7554\n",
            "Epoch [12/100], Step [8000/12500], Loss: 0.5771\n",
            "Epoch [12/100], Step [10000/12500], Loss: 0.7582\n",
            "Epoch [12/100], Step [12000/12500], Loss: 2.0520\n",
            "Epoch [13/100], Step [2000/12500], Loss: 0.8113\n",
            "Epoch [13/100], Step [4000/12500], Loss: 1.6656\n",
            "Epoch [13/100], Step [6000/12500], Loss: 0.5785\n",
            "Epoch [13/100], Step [8000/12500], Loss: 1.7852\n",
            "Epoch [13/100], Step [10000/12500], Loss: 2.2358\n",
            "Epoch [13/100], Step [12000/12500], Loss: 0.5981\n",
            "Epoch [14/100], Step [2000/12500], Loss: 1.5806\n",
            "Epoch [14/100], Step [4000/12500], Loss: 0.8590\n",
            "Epoch [14/100], Step [6000/12500], Loss: 1.1704\n",
            "Epoch [14/100], Step [8000/12500], Loss: 0.8909\n",
            "Epoch [14/100], Step [10000/12500], Loss: 1.0587\n",
            "Epoch [14/100], Step [12000/12500], Loss: 0.8090\n",
            "Epoch [15/100], Step [2000/12500], Loss: 1.4862\n",
            "Epoch [15/100], Step [4000/12500], Loss: 1.0586\n",
            "Epoch [15/100], Step [6000/12500], Loss: 0.8017\n",
            "Epoch [15/100], Step [8000/12500], Loss: 1.2137\n",
            "Epoch [15/100], Step [10000/12500], Loss: 0.7710\n",
            "Epoch [15/100], Step [12000/12500], Loss: 1.9888\n",
            "Epoch [16/100], Step [2000/12500], Loss: 0.5750\n",
            "Epoch [16/100], Step [4000/12500], Loss: 1.7680\n",
            "Epoch [16/100], Step [6000/12500], Loss: 1.1438\n",
            "Epoch [16/100], Step [8000/12500], Loss: 2.5844\n",
            "Epoch [16/100], Step [10000/12500], Loss: 1.5979\n",
            "Epoch [16/100], Step [12000/12500], Loss: 1.5071\n",
            "Epoch [17/100], Step [2000/12500], Loss: 0.0887\n",
            "Epoch [17/100], Step [4000/12500], Loss: 0.5360\n",
            "Epoch [17/100], Step [6000/12500], Loss: 0.7117\n",
            "Epoch [17/100], Step [8000/12500], Loss: 0.4719\n",
            "Epoch [17/100], Step [10000/12500], Loss: 1.0586\n",
            "Epoch [17/100], Step [12000/12500], Loss: 1.2043\n",
            "Epoch [18/100], Step [2000/12500], Loss: 1.5724\n",
            "Epoch [18/100], Step [4000/12500], Loss: 0.9597\n",
            "Epoch [18/100], Step [6000/12500], Loss: 1.4381\n",
            "Epoch [18/100], Step [8000/12500], Loss: 0.4177\n",
            "Epoch [18/100], Step [10000/12500], Loss: 0.7221\n",
            "Epoch [18/100], Step [12000/12500], Loss: 1.3682\n",
            "Epoch [19/100], Step [2000/12500], Loss: 0.9965\n",
            "Epoch [19/100], Step [4000/12500], Loss: 0.6720\n",
            "Epoch [19/100], Step [6000/12500], Loss: 0.4562\n",
            "Epoch [19/100], Step [8000/12500], Loss: 0.7163\n",
            "Epoch [19/100], Step [10000/12500], Loss: 0.4375\n",
            "Epoch [19/100], Step [12000/12500], Loss: 0.5679\n",
            "Epoch [20/100], Step [2000/12500], Loss: 0.5169\n",
            "Epoch [20/100], Step [4000/12500], Loss: 0.4194\n",
            "Epoch [20/100], Step [6000/12500], Loss: 0.7438\n",
            "Epoch [20/100], Step [8000/12500], Loss: 1.3646\n",
            "Epoch [20/100], Step [10000/12500], Loss: 0.3493\n",
            "Epoch [20/100], Step [12000/12500], Loss: 0.9258\n",
            "Epoch [21/100], Step [2000/12500], Loss: 0.9757\n",
            "Epoch [21/100], Step [4000/12500], Loss: 1.0872\n",
            "Epoch [21/100], Step [6000/12500], Loss: 1.0089\n",
            "Epoch [21/100], Step [8000/12500], Loss: 0.1410\n",
            "Epoch [21/100], Step [10000/12500], Loss: 1.1451\n",
            "Epoch [21/100], Step [12000/12500], Loss: 0.4447\n",
            "Epoch [22/100], Step [2000/12500], Loss: 1.7745\n",
            "Epoch [22/100], Step [4000/12500], Loss: 0.1733\n",
            "Epoch [22/100], Step [6000/12500], Loss: 0.9481\n",
            "Epoch [22/100], Step [8000/12500], Loss: 0.5897\n",
            "Epoch [22/100], Step [10000/12500], Loss: 0.1517\n",
            "Epoch [22/100], Step [12000/12500], Loss: 1.7135\n",
            "Epoch [23/100], Step [2000/12500], Loss: 2.2891\n",
            "Epoch [23/100], Step [4000/12500], Loss: 0.5999\n",
            "Epoch [23/100], Step [6000/12500], Loss: 1.2660\n",
            "Epoch [23/100], Step [8000/12500], Loss: 0.6218\n",
            "Epoch [23/100], Step [10000/12500], Loss: 1.1217\n",
            "Epoch [23/100], Step [12000/12500], Loss: 1.2975\n",
            "Epoch [24/100], Step [2000/12500], Loss: 1.2140\n",
            "Epoch [24/100], Step [4000/12500], Loss: 0.6808\n",
            "Epoch [24/100], Step [6000/12500], Loss: 0.7598\n",
            "Epoch [24/100], Step [8000/12500], Loss: 0.4441\n",
            "Epoch [24/100], Step [10000/12500], Loss: 0.0923\n",
            "Epoch [24/100], Step [12000/12500], Loss: 0.7382\n",
            "Epoch [25/100], Step [2000/12500], Loss: 0.6904\n",
            "Epoch [25/100], Step [4000/12500], Loss: 1.4931\n",
            "Epoch [25/100], Step [6000/12500], Loss: 0.6580\n",
            "Epoch [25/100], Step [8000/12500], Loss: 1.4624\n",
            "Epoch [25/100], Step [10000/12500], Loss: 0.0114\n",
            "Epoch [25/100], Step [12000/12500], Loss: 0.3535\n",
            "Epoch [26/100], Step [2000/12500], Loss: 0.2014\n",
            "Epoch [26/100], Step [4000/12500], Loss: 0.3414\n",
            "Epoch [26/100], Step [6000/12500], Loss: 1.3141\n",
            "Epoch [26/100], Step [8000/12500], Loss: 0.1738\n",
            "Epoch [26/100], Step [10000/12500], Loss: 0.4685\n",
            "Epoch [26/100], Step [12000/12500], Loss: 0.6082\n",
            "Epoch [27/100], Step [2000/12500], Loss: 1.3153\n",
            "Epoch [27/100], Step [4000/12500], Loss: 1.2877\n",
            "Epoch [27/100], Step [6000/12500], Loss: 0.6210\n",
            "Epoch [27/100], Step [8000/12500], Loss: 1.0873\n",
            "Epoch [27/100], Step [10000/12500], Loss: 1.8515\n",
            "Epoch [27/100], Step [12000/12500], Loss: 0.9111\n",
            "Epoch [28/100], Step [2000/12500], Loss: 1.2158\n",
            "Epoch [28/100], Step [4000/12500], Loss: 0.6060\n",
            "Epoch [28/100], Step [6000/12500], Loss: 0.5649\n",
            "Epoch [28/100], Step [8000/12500], Loss: 0.4963\n",
            "Epoch [28/100], Step [10000/12500], Loss: 0.7902\n",
            "Epoch [28/100], Step [12000/12500], Loss: 1.0030\n",
            "Epoch [29/100], Step [2000/12500], Loss: 1.2405\n",
            "Epoch [29/100], Step [4000/12500], Loss: 0.1631\n",
            "Epoch [29/100], Step [6000/12500], Loss: 0.6037\n",
            "Epoch [29/100], Step [8000/12500], Loss: 1.0048\n",
            "Epoch [29/100], Step [10000/12500], Loss: 0.0187\n",
            "Epoch [29/100], Step [12000/12500], Loss: 0.2662\n",
            "Epoch [30/100], Step [2000/12500], Loss: 0.9878\n",
            "Epoch [30/100], Step [4000/12500], Loss: 1.1830\n",
            "Epoch [30/100], Step [6000/12500], Loss: 2.5828\n",
            "Epoch [30/100], Step [8000/12500], Loss: 0.3648\n",
            "Epoch [30/100], Step [10000/12500], Loss: 1.5679\n",
            "Epoch [30/100], Step [12000/12500], Loss: 0.5378\n",
            "Epoch [31/100], Step [2000/12500], Loss: 0.4941\n",
            "Epoch [31/100], Step [4000/12500], Loss: 0.4300\n",
            "Epoch [31/100], Step [6000/12500], Loss: 1.3071\n",
            "Epoch [31/100], Step [8000/12500], Loss: 0.6126\n",
            "Epoch [31/100], Step [10000/12500], Loss: 0.6806\n",
            "Epoch [31/100], Step [12000/12500], Loss: 1.7147\n",
            "Epoch [32/100], Step [2000/12500], Loss: 1.7268\n",
            "Epoch [32/100], Step [4000/12500], Loss: 0.4815\n",
            "Epoch [32/100], Step [6000/12500], Loss: 0.6424\n",
            "Epoch [32/100], Step [8000/12500], Loss: 0.4123\n",
            "Epoch [32/100], Step [10000/12500], Loss: 0.8932\n",
            "Epoch [32/100], Step [12000/12500], Loss: 1.4705\n",
            "Epoch [33/100], Step [2000/12500], Loss: 0.1353\n",
            "Epoch [33/100], Step [4000/12500], Loss: 0.6734\n",
            "Epoch [33/100], Step [6000/12500], Loss: 0.7255\n",
            "Epoch [33/100], Step [8000/12500], Loss: 1.1278\n",
            "Epoch [33/100], Step [10000/12500], Loss: 0.5791\n",
            "Epoch [33/100], Step [12000/12500], Loss: 0.3495\n",
            "Epoch [34/100], Step [2000/12500], Loss: 0.5157\n",
            "Epoch [34/100], Step [4000/12500], Loss: 1.0592\n",
            "Epoch [34/100], Step [6000/12500], Loss: 0.7210\n",
            "Epoch [34/100], Step [8000/12500], Loss: 0.0381\n",
            "Epoch [34/100], Step [10000/12500], Loss: 1.2000\n",
            "Epoch [34/100], Step [12000/12500], Loss: 0.3092\n",
            "Epoch [35/100], Step [2000/12500], Loss: 1.0077\n",
            "Epoch [35/100], Step [4000/12500], Loss: 0.4327\n",
            "Epoch [35/100], Step [6000/12500], Loss: 1.1785\n",
            "Epoch [35/100], Step [8000/12500], Loss: 0.4667\n",
            "Epoch [35/100], Step [10000/12500], Loss: 0.9066\n",
            "Epoch [35/100], Step [12000/12500], Loss: 1.1696\n",
            "Epoch [36/100], Step [2000/12500], Loss: 0.1194\n",
            "Epoch [36/100], Step [4000/12500], Loss: 0.9398\n",
            "Epoch [36/100], Step [6000/12500], Loss: 0.6076\n",
            "Epoch [36/100], Step [8000/12500], Loss: 0.6663\n",
            "Epoch [36/100], Step [10000/12500], Loss: 0.4566\n",
            "Epoch [36/100], Step [12000/12500], Loss: 0.2334\n",
            "Epoch [37/100], Step [2000/12500], Loss: 0.0976\n",
            "Epoch [37/100], Step [4000/12500], Loss: 0.5267\n",
            "Epoch [37/100], Step [6000/12500], Loss: 0.8563\n",
            "Epoch [37/100], Step [8000/12500], Loss: 0.4746\n",
            "Epoch [37/100], Step [10000/12500], Loss: 0.3087\n",
            "Epoch [37/100], Step [12000/12500], Loss: 0.3966\n",
            "Epoch [38/100], Step [2000/12500], Loss: 0.3336\n",
            "Epoch [38/100], Step [4000/12500], Loss: 0.5194\n",
            "Epoch [38/100], Step [6000/12500], Loss: 0.1317\n",
            "Epoch [38/100], Step [8000/12500], Loss: 0.4441\n",
            "Epoch [38/100], Step [10000/12500], Loss: 0.2869\n",
            "Epoch [38/100], Step [12000/12500], Loss: 0.8950\n",
            "Epoch [39/100], Step [2000/12500], Loss: 0.4071\n",
            "Epoch [39/100], Step [4000/12500], Loss: 0.9277\n",
            "Epoch [39/100], Step [6000/12500], Loss: 0.7167\n",
            "Epoch [39/100], Step [8000/12500], Loss: 0.8168\n",
            "Epoch [39/100], Step [10000/12500], Loss: 0.3670\n",
            "Epoch [39/100], Step [12000/12500], Loss: 0.4750\n",
            "Epoch [40/100], Step [2000/12500], Loss: 0.8062\n",
            "Epoch [40/100], Step [4000/12500], Loss: 0.4925\n",
            "Epoch [40/100], Step [6000/12500], Loss: 0.2708\n",
            "Epoch [40/100], Step [8000/12500], Loss: 0.8274\n",
            "Epoch [40/100], Step [10000/12500], Loss: 0.6626\n",
            "Epoch [40/100], Step [12000/12500], Loss: 0.6661\n",
            "Epoch [41/100], Step [2000/12500], Loss: 0.9947\n",
            "Epoch [41/100], Step [4000/12500], Loss: 0.2210\n",
            "Epoch [41/100], Step [6000/12500], Loss: 0.7530\n",
            "Epoch [41/100], Step [8000/12500], Loss: 0.7197\n",
            "Epoch [41/100], Step [10000/12500], Loss: 0.5169\n",
            "Epoch [41/100], Step [12000/12500], Loss: 0.3622\n",
            "Epoch [42/100], Step [2000/12500], Loss: 0.2937\n",
            "Epoch [42/100], Step [4000/12500], Loss: 0.1404\n",
            "Epoch [42/100], Step [6000/12500], Loss: 0.2408\n",
            "Epoch [42/100], Step [8000/12500], Loss: 0.0928\n",
            "Epoch [42/100], Step [10000/12500], Loss: 0.3934\n",
            "Epoch [42/100], Step [12000/12500], Loss: 1.1004\n",
            "Epoch [43/100], Step [2000/12500], Loss: 0.0545\n",
            "Epoch [43/100], Step [4000/12500], Loss: 0.8521\n",
            "Epoch [43/100], Step [6000/12500], Loss: 0.5127\n",
            "Epoch [43/100], Step [8000/12500], Loss: 0.6071\n",
            "Epoch [43/100], Step [10000/12500], Loss: 0.8202\n",
            "Epoch [43/100], Step [12000/12500], Loss: 0.8876\n",
            "Epoch [44/100], Step [2000/12500], Loss: 0.4065\n",
            "Epoch [44/100], Step [4000/12500], Loss: 0.2736\n",
            "Epoch [44/100], Step [6000/12500], Loss: 0.3882\n",
            "Epoch [44/100], Step [8000/12500], Loss: 0.0276\n",
            "Epoch [44/100], Step [10000/12500], Loss: 0.0696\n",
            "Epoch [44/100], Step [12000/12500], Loss: 0.8586\n",
            "Epoch [45/100], Step [2000/12500], Loss: 0.5406\n",
            "Epoch [45/100], Step [4000/12500], Loss: 0.5730\n",
            "Epoch [45/100], Step [6000/12500], Loss: 0.2671\n",
            "Epoch [45/100], Step [8000/12500], Loss: 1.0662\n",
            "Epoch [45/100], Step [10000/12500], Loss: 0.1181\n",
            "Epoch [45/100], Step [12000/12500], Loss: 0.1530\n",
            "Epoch [46/100], Step [2000/12500], Loss: 0.1637\n",
            "Epoch [46/100], Step [4000/12500], Loss: 0.8411\n",
            "Epoch [46/100], Step [6000/12500], Loss: 0.1604\n",
            "Epoch [46/100], Step [8000/12500], Loss: 1.1181\n",
            "Epoch [46/100], Step [10000/12500], Loss: 0.0625\n",
            "Epoch [46/100], Step [12000/12500], Loss: 0.2945\n",
            "Epoch [47/100], Step [2000/12500], Loss: 0.2206\n",
            "Epoch [47/100], Step [4000/12500], Loss: 0.4053\n",
            "Epoch [47/100], Step [6000/12500], Loss: 0.6532\n",
            "Epoch [47/100], Step [8000/12500], Loss: 0.0805\n",
            "Epoch [47/100], Step [10000/12500], Loss: 0.0147\n",
            "Epoch [47/100], Step [12000/12500], Loss: 0.0448\n",
            "Epoch [48/100], Step [2000/12500], Loss: 0.3866\n",
            "Epoch [48/100], Step [4000/12500], Loss: 0.1759\n",
            "Epoch [48/100], Step [6000/12500], Loss: 1.0989\n",
            "Epoch [48/100], Step [8000/12500], Loss: 0.0933\n",
            "Epoch [48/100], Step [10000/12500], Loss: 0.1620\n",
            "Epoch [48/100], Step [12000/12500], Loss: 0.1367\n",
            "Epoch [49/100], Step [2000/12500], Loss: 0.0009\n",
            "Epoch [49/100], Step [4000/12500], Loss: 0.7978\n",
            "Epoch [49/100], Step [6000/12500], Loss: 0.1168\n",
            "Epoch [49/100], Step [8000/12500], Loss: 0.2066\n",
            "Epoch [49/100], Step [10000/12500], Loss: 0.0272\n",
            "Epoch [49/100], Step [12000/12500], Loss: 0.5091\n",
            "Epoch [50/100], Step [2000/12500], Loss: 0.1437\n",
            "Epoch [50/100], Step [4000/12500], Loss: 0.2308\n",
            "Epoch [50/100], Step [6000/12500], Loss: 0.2646\n",
            "Epoch [50/100], Step [8000/12500], Loss: 1.2092\n",
            "Epoch [50/100], Step [10000/12500], Loss: 0.0515\n",
            "Epoch [50/100], Step [12000/12500], Loss: 0.7885\n",
            "Epoch [51/100], Step [2000/12500], Loss: 0.1347\n",
            "Epoch [51/100], Step [4000/12500], Loss: 0.0148\n",
            "Epoch [51/100], Step [6000/12500], Loss: 0.1217\n",
            "Epoch [51/100], Step [8000/12500], Loss: 0.0325\n",
            "Epoch [51/100], Step [10000/12500], Loss: 0.5431\n",
            "Epoch [51/100], Step [12000/12500], Loss: 0.6018\n",
            "Epoch [52/100], Step [2000/12500], Loss: 0.3612\n",
            "Epoch [52/100], Step [4000/12500], Loss: 0.9371\n",
            "Epoch [52/100], Step [6000/12500], Loss: 0.3186\n",
            "Epoch [52/100], Step [8000/12500], Loss: 0.5686\n",
            "Epoch [52/100], Step [10000/12500], Loss: 0.5869\n",
            "Epoch [52/100], Step [12000/12500], Loss: 1.0453\n",
            "Epoch [53/100], Step [2000/12500], Loss: 1.8174\n",
            "Epoch [53/100], Step [4000/12500], Loss: 0.0444\n",
            "Epoch [53/100], Step [6000/12500], Loss: 0.0608\n",
            "Epoch [53/100], Step [8000/12500], Loss: 0.4104\n",
            "Epoch [53/100], Step [10000/12500], Loss: 0.2850\n",
            "Epoch [53/100], Step [12000/12500], Loss: 1.3248\n",
            "Epoch [54/100], Step [2000/12500], Loss: 0.4496\n",
            "Epoch [54/100], Step [4000/12500], Loss: 1.0619\n",
            "Epoch [54/100], Step [6000/12500], Loss: 0.2583\n",
            "Epoch [54/100], Step [8000/12500], Loss: 0.7493\n",
            "Epoch [54/100], Step [10000/12500], Loss: 0.4377\n",
            "Epoch [54/100], Step [12000/12500], Loss: 0.4286\n",
            "Epoch [55/100], Step [2000/12500], Loss: 0.0263\n",
            "Epoch [55/100], Step [4000/12500], Loss: 0.0055\n",
            "Epoch [55/100], Step [6000/12500], Loss: 1.0347\n",
            "Epoch [55/100], Step [8000/12500], Loss: 0.0798\n",
            "Epoch [55/100], Step [10000/12500], Loss: 0.6293\n",
            "Epoch [55/100], Step [12000/12500], Loss: 0.7323\n",
            "Epoch [56/100], Step [2000/12500], Loss: 0.2809\n",
            "Epoch [56/100], Step [4000/12500], Loss: 0.1692\n",
            "Epoch [56/100], Step [6000/12500], Loss: 0.0055\n",
            "Epoch [56/100], Step [8000/12500], Loss: 0.4295\n",
            "Epoch [56/100], Step [10000/12500], Loss: 0.0876\n",
            "Epoch [56/100], Step [12000/12500], Loss: 1.6312\n",
            "Epoch [57/100], Step [2000/12500], Loss: 0.0788\n",
            "Epoch [57/100], Step [4000/12500], Loss: 0.4781\n",
            "Epoch [57/100], Step [6000/12500], Loss: 0.0868\n",
            "Epoch [57/100], Step [8000/12500], Loss: 0.2237\n",
            "Epoch [57/100], Step [10000/12500], Loss: 0.8333\n",
            "Epoch [57/100], Step [12000/12500], Loss: 0.8302\n",
            "Epoch [58/100], Step [2000/12500], Loss: 0.2291\n",
            "Epoch [58/100], Step [4000/12500], Loss: 0.3638\n",
            "Epoch [58/100], Step [6000/12500], Loss: 1.8434\n",
            "Epoch [58/100], Step [8000/12500], Loss: 0.8257\n",
            "Epoch [58/100], Step [10000/12500], Loss: 0.2657\n",
            "Epoch [58/100], Step [12000/12500], Loss: 0.6619\n",
            "Epoch [59/100], Step [2000/12500], Loss: 0.0692\n",
            "Epoch [59/100], Step [4000/12500], Loss: 0.6598\n",
            "Epoch [59/100], Step [6000/12500], Loss: 0.6077\n",
            "Epoch [59/100], Step [8000/12500], Loss: 0.7565\n",
            "Epoch [59/100], Step [10000/12500], Loss: 0.4147\n",
            "Epoch [59/100], Step [12000/12500], Loss: 0.2989\n",
            "Epoch [60/100], Step [2000/12500], Loss: 0.0121\n",
            "Epoch [60/100], Step [4000/12500], Loss: 0.9033\n",
            "Epoch [60/100], Step [6000/12500], Loss: 0.1522\n",
            "Epoch [60/100], Step [8000/12500], Loss: 1.4777\n",
            "Epoch [60/100], Step [10000/12500], Loss: 0.0011\n",
            "Epoch [60/100], Step [12000/12500], Loss: 0.0792\n",
            "Epoch [61/100], Step [2000/12500], Loss: 0.0024\n",
            "Epoch [61/100], Step [4000/12500], Loss: 0.2097\n",
            "Epoch [61/100], Step [6000/12500], Loss: 0.0975\n",
            "Epoch [61/100], Step [8000/12500], Loss: 0.4097\n",
            "Epoch [61/100], Step [10000/12500], Loss: 0.0992\n",
            "Epoch [61/100], Step [12000/12500], Loss: 0.3758\n",
            "Epoch [62/100], Step [2000/12500], Loss: 0.0878\n",
            "Epoch [62/100], Step [4000/12500], Loss: 0.0122\n",
            "Epoch [62/100], Step [6000/12500], Loss: 0.6475\n",
            "Epoch [62/100], Step [8000/12500], Loss: 0.3370\n",
            "Epoch [62/100], Step [10000/12500], Loss: 0.3646\n",
            "Epoch [62/100], Step [12000/12500], Loss: 0.2905\n",
            "Epoch [63/100], Step [2000/12500], Loss: 0.4154\n",
            "Epoch [63/100], Step [4000/12500], Loss: 0.6916\n",
            "Epoch [63/100], Step [6000/12500], Loss: 0.3054\n",
            "Epoch [63/100], Step [8000/12500], Loss: 0.0132\n",
            "Epoch [63/100], Step [10000/12500], Loss: 0.0267\n",
            "Epoch [63/100], Step [12000/12500], Loss: 0.2306\n",
            "Epoch [64/100], Step [2000/12500], Loss: 0.0202\n",
            "Epoch [64/100], Step [4000/12500], Loss: 0.0132\n",
            "Epoch [64/100], Step [6000/12500], Loss: 0.2686\n",
            "Epoch [64/100], Step [8000/12500], Loss: 0.0402\n",
            "Epoch [64/100], Step [10000/12500], Loss: 0.0724\n",
            "Epoch [64/100], Step [12000/12500], Loss: 0.1974\n",
            "Epoch [65/100], Step [2000/12500], Loss: 0.4663\n",
            "Epoch [65/100], Step [4000/12500], Loss: 0.0062\n",
            "Epoch [65/100], Step [6000/12500], Loss: 0.2575\n",
            "Epoch [65/100], Step [8000/12500], Loss: 0.1147\n",
            "Epoch [65/100], Step [10000/12500], Loss: 0.0639\n",
            "Epoch [65/100], Step [12000/12500], Loss: 0.1369\n",
            "Epoch [66/100], Step [2000/12500], Loss: 0.0221\n",
            "Epoch [66/100], Step [4000/12500], Loss: 0.3992\n",
            "Epoch [66/100], Step [6000/12500], Loss: 0.5105\n",
            "Epoch [66/100], Step [8000/12500], Loss: 0.0831\n",
            "Epoch [66/100], Step [10000/12500], Loss: 0.1752\n",
            "Epoch [66/100], Step [12000/12500], Loss: 0.0822\n",
            "Epoch [67/100], Step [2000/12500], Loss: 0.1302\n",
            "Epoch [67/100], Step [4000/12500], Loss: 0.1451\n",
            "Epoch [67/100], Step [6000/12500], Loss: 0.0289\n",
            "Epoch [67/100], Step [8000/12500], Loss: 0.0393\n",
            "Epoch [67/100], Step [10000/12500], Loss: 0.1386\n",
            "Epoch [67/100], Step [12000/12500], Loss: 0.0633\n",
            "Epoch [68/100], Step [2000/12500], Loss: 0.0822\n",
            "Epoch [68/100], Step [4000/12500], Loss: 0.2779\n",
            "Epoch [68/100], Step [6000/12500], Loss: 0.0029\n",
            "Epoch [68/100], Step [8000/12500], Loss: 0.4230\n",
            "Epoch [68/100], Step [10000/12500], Loss: 0.3139\n",
            "Epoch [68/100], Step [12000/12500], Loss: 0.4461\n",
            "Epoch [69/100], Step [2000/12500], Loss: 0.4628\n",
            "Epoch [69/100], Step [4000/12500], Loss: 0.9703\n",
            "Epoch [69/100], Step [6000/12500], Loss: 0.3977\n",
            "Epoch [69/100], Step [8000/12500], Loss: 0.1409\n",
            "Epoch [69/100], Step [10000/12500], Loss: 2.7885\n",
            "Epoch [69/100], Step [12000/12500], Loss: 0.0147\n",
            "Epoch [70/100], Step [2000/12500], Loss: 0.4620\n",
            "Epoch [70/100], Step [4000/12500], Loss: 0.3127\n",
            "Epoch [70/100], Step [6000/12500], Loss: 0.3519\n",
            "Epoch [70/100], Step [8000/12500], Loss: 0.1676\n",
            "Epoch [70/100], Step [10000/12500], Loss: 0.7296\n",
            "Epoch [70/100], Step [12000/12500], Loss: 0.7010\n",
            "Epoch [71/100], Step [2000/12500], Loss: 0.2974\n",
            "Epoch [71/100], Step [4000/12500], Loss: 0.3093\n",
            "Epoch [71/100], Step [6000/12500], Loss: 0.9431\n",
            "Epoch [71/100], Step [8000/12500], Loss: 0.6573\n",
            "Epoch [71/100], Step [10000/12500], Loss: 0.3018\n",
            "Epoch [71/100], Step [12000/12500], Loss: 0.5387\n",
            "Epoch [72/100], Step [2000/12500], Loss: 0.2830\n",
            "Epoch [72/100], Step [4000/12500], Loss: 0.1450\n",
            "Epoch [72/100], Step [6000/12500], Loss: 0.0520\n",
            "Epoch [72/100], Step [8000/12500], Loss: 0.1023\n",
            "Epoch [72/100], Step [10000/12500], Loss: 0.1768\n",
            "Epoch [72/100], Step [12000/12500], Loss: 0.6806\n",
            "Epoch [73/100], Step [2000/12500], Loss: 0.0517\n",
            "Epoch [73/100], Step [4000/12500], Loss: 0.0296\n",
            "Epoch [73/100], Step [6000/12500], Loss: 0.2132\n",
            "Epoch [73/100], Step [8000/12500], Loss: 0.0588\n",
            "Epoch [73/100], Step [10000/12500], Loss: 0.0000\n",
            "Epoch [73/100], Step [12000/12500], Loss: 0.7179\n",
            "Epoch [74/100], Step [2000/12500], Loss: 0.7679\n",
            "Epoch [74/100], Step [4000/12500], Loss: 0.0316\n",
            "Epoch [74/100], Step [6000/12500], Loss: 0.2055\n",
            "Epoch [74/100], Step [8000/12500], Loss: 0.0350\n",
            "Epoch [74/100], Step [10000/12500], Loss: 0.6500\n",
            "Epoch [74/100], Step [12000/12500], Loss: 0.3861\n",
            "Epoch [75/100], Step [2000/12500], Loss: 0.0472\n",
            "Epoch [75/100], Step [4000/12500], Loss: 0.1249\n",
            "Epoch [75/100], Step [6000/12500], Loss: 0.2907\n",
            "Epoch [75/100], Step [8000/12500], Loss: 1.1169\n",
            "Epoch [75/100], Step [10000/12500], Loss: 0.1217\n",
            "Epoch [75/100], Step [12000/12500], Loss: 0.0199\n",
            "Epoch [76/100], Step [2000/12500], Loss: 0.0278\n",
            "Epoch [76/100], Step [4000/12500], Loss: 0.3079\n",
            "Epoch [76/100], Step [6000/12500], Loss: 0.1644\n",
            "Epoch [76/100], Step [8000/12500], Loss: 1.7653\n",
            "Epoch [76/100], Step [10000/12500], Loss: 0.0382\n",
            "Epoch [76/100], Step [12000/12500], Loss: 0.0334\n",
            "Epoch [77/100], Step [2000/12500], Loss: 0.0039\n",
            "Epoch [77/100], Step [4000/12500], Loss: 0.0040\n",
            "Epoch [77/100], Step [6000/12500], Loss: 0.1131\n",
            "Epoch [77/100], Step [8000/12500], Loss: 0.0046\n",
            "Epoch [77/100], Step [10000/12500], Loss: 0.4023\n",
            "Epoch [77/100], Step [12000/12500], Loss: 0.0196\n",
            "Epoch [78/100], Step [2000/12500], Loss: 0.0417\n",
            "Epoch [78/100], Step [4000/12500], Loss: 0.7373\n",
            "Epoch [78/100], Step [6000/12500], Loss: 0.1908\n",
            "Epoch [78/100], Step [8000/12500], Loss: 0.1013\n",
            "Epoch [78/100], Step [10000/12500], Loss: 0.2662\n",
            "Epoch [78/100], Step [12000/12500], Loss: 0.5503\n",
            "Epoch [79/100], Step [2000/12500], Loss: 0.0093\n",
            "Epoch [79/100], Step [4000/12500], Loss: 0.1261\n",
            "Epoch [79/100], Step [6000/12500], Loss: 0.0504\n",
            "Epoch [79/100], Step [8000/12500], Loss: 0.7670\n",
            "Epoch [79/100], Step [10000/12500], Loss: 0.0054\n",
            "Epoch [79/100], Step [12000/12500], Loss: 0.2771\n",
            "Epoch [80/100], Step [2000/12500], Loss: 0.0100\n",
            "Epoch [80/100], Step [4000/12500], Loss: 0.0599\n",
            "Epoch [80/100], Step [6000/12500], Loss: 0.2887\n",
            "Epoch [80/100], Step [8000/12500], Loss: 0.1222\n",
            "Epoch [80/100], Step [10000/12500], Loss: 0.0008\n",
            "Epoch [80/100], Step [12000/12500], Loss: 0.0035\n",
            "Epoch [81/100], Step [2000/12500], Loss: 0.0039\n",
            "Epoch [81/100], Step [4000/12500], Loss: 0.0733\n",
            "Epoch [81/100], Step [6000/12500], Loss: 0.0009\n",
            "Epoch [81/100], Step [8000/12500], Loss: 0.1823\n",
            "Epoch [81/100], Step [10000/12500], Loss: 0.0864\n",
            "Epoch [81/100], Step [12000/12500], Loss: 0.0079\n",
            "Epoch [82/100], Step [2000/12500], Loss: 0.1396\n",
            "Epoch [82/100], Step [4000/12500], Loss: 0.1919\n",
            "Epoch [82/100], Step [6000/12500], Loss: 0.4264\n",
            "Epoch [82/100], Step [8000/12500], Loss: 0.0344\n",
            "Epoch [82/100], Step [10000/12500], Loss: 0.3085\n",
            "Epoch [82/100], Step [12000/12500], Loss: 0.0365\n",
            "Epoch [83/100], Step [2000/12500], Loss: 0.0012\n",
            "Epoch [83/100], Step [4000/12500], Loss: 0.0429\n",
            "Epoch [83/100], Step [6000/12500], Loss: 0.1641\n",
            "Epoch [83/100], Step [8000/12500], Loss: 0.0050\n",
            "Epoch [83/100], Step [10000/12500], Loss: 0.1400\n",
            "Epoch [83/100], Step [12000/12500], Loss: 0.2116\n",
            "Epoch [84/100], Step [2000/12500], Loss: 0.0853\n",
            "Epoch [84/100], Step [4000/12500], Loss: 0.2043\n",
            "Epoch [84/100], Step [6000/12500], Loss: 0.2942\n",
            "Epoch [84/100], Step [8000/12500], Loss: 0.1823\n",
            "Epoch [84/100], Step [10000/12500], Loss: 0.5162\n",
            "Epoch [84/100], Step [12000/12500], Loss: 0.0000\n",
            "Epoch [85/100], Step [2000/12500], Loss: 0.1484\n",
            "Epoch [85/100], Step [4000/12500], Loss: 0.0304\n",
            "Epoch [85/100], Step [6000/12500], Loss: 0.0195\n",
            "Epoch [85/100], Step [8000/12500], Loss: 0.0038\n",
            "Epoch [85/100], Step [10000/12500], Loss: 0.3138\n",
            "Epoch [85/100], Step [12000/12500], Loss: 0.0153\n",
            "Epoch [86/100], Step [2000/12500], Loss: 0.1344\n",
            "Epoch [86/100], Step [4000/12500], Loss: 0.0113\n",
            "Epoch [86/100], Step [6000/12500], Loss: 0.2956\n",
            "Epoch [86/100], Step [8000/12500], Loss: 0.0195\n",
            "Epoch [86/100], Step [10000/12500], Loss: 0.3563\n",
            "Epoch [86/100], Step [12000/12500], Loss: 0.0543\n",
            "Epoch [87/100], Step [2000/12500], Loss: 0.0325\n",
            "Epoch [87/100], Step [4000/12500], Loss: 0.2624\n",
            "Epoch [87/100], Step [6000/12500], Loss: 0.0010\n",
            "Epoch [87/100], Step [8000/12500], Loss: 0.0775\n",
            "Epoch [87/100], Step [10000/12500], Loss: 0.0546\n",
            "Epoch [87/100], Step [12000/12500], Loss: 0.3417\n",
            "Epoch [88/100], Step [2000/12500], Loss: 0.0371\n",
            "Epoch [88/100], Step [4000/12500], Loss: 0.0016\n",
            "Epoch [88/100], Step [6000/12500], Loss: 0.7898\n",
            "Epoch [88/100], Step [8000/12500], Loss: 0.0432\n",
            "Epoch [88/100], Step [10000/12500], Loss: 0.0579\n",
            "Epoch [88/100], Step [12000/12500], Loss: 0.0839\n",
            "Epoch [89/100], Step [2000/12500], Loss: 0.3003\n",
            "Epoch [89/100], Step [4000/12500], Loss: 0.0132\n",
            "Epoch [89/100], Step [6000/12500], Loss: 0.0124\n",
            "Epoch [89/100], Step [8000/12500], Loss: 0.2682\n",
            "Epoch [89/100], Step [10000/12500], Loss: 0.1722\n",
            "Epoch [89/100], Step [12000/12500], Loss: 0.0591\n",
            "Epoch [90/100], Step [2000/12500], Loss: 0.0083\n",
            "Epoch [90/100], Step [4000/12500], Loss: 0.0074\n",
            "Epoch [90/100], Step [6000/12500], Loss: 0.0060\n",
            "Epoch [90/100], Step [8000/12500], Loss: 0.2175\n",
            "Epoch [90/100], Step [10000/12500], Loss: 0.2265\n",
            "Epoch [90/100], Step [12000/12500], Loss: 0.0348\n",
            "Epoch [91/100], Step [2000/12500], Loss: 0.0308\n",
            "Epoch [91/100], Step [4000/12500], Loss: 0.0753\n",
            "Epoch [91/100], Step [6000/12500], Loss: 0.0437\n",
            "Epoch [91/100], Step [8000/12500], Loss: 0.0922\n",
            "Epoch [91/100], Step [10000/12500], Loss: 2.0461\n",
            "Epoch [91/100], Step [12000/12500], Loss: 0.3542\n",
            "Epoch [92/100], Step [2000/12500], Loss: 0.0324\n",
            "Epoch [92/100], Step [4000/12500], Loss: 0.0029\n",
            "Epoch [92/100], Step [6000/12500], Loss: 0.3476\n",
            "Epoch [92/100], Step [8000/12500], Loss: 0.0651\n",
            "Epoch [92/100], Step [10000/12500], Loss: 0.0999\n",
            "Epoch [92/100], Step [12000/12500], Loss: 0.9107\n",
            "Epoch [93/100], Step [2000/12500], Loss: 0.0203\n",
            "Epoch [93/100], Step [4000/12500], Loss: 0.0003\n",
            "Epoch [93/100], Step [6000/12500], Loss: 0.3461\n",
            "Epoch [93/100], Step [8000/12500], Loss: 0.3114\n",
            "Epoch [93/100], Step [10000/12500], Loss: 0.0003\n",
            "Epoch [93/100], Step [12000/12500], Loss: 0.0088\n",
            "Epoch [94/100], Step [2000/12500], Loss: 0.9036\n",
            "Epoch [94/100], Step [4000/12500], Loss: 0.0067\n",
            "Epoch [94/100], Step [6000/12500], Loss: 0.0274\n",
            "Epoch [94/100], Step [8000/12500], Loss: 0.1641\n",
            "Epoch [94/100], Step [10000/12500], Loss: 0.0310\n",
            "Epoch [94/100], Step [12000/12500], Loss: 0.1575\n",
            "Epoch [95/100], Step [2000/12500], Loss: 0.0301\n",
            "Epoch [95/100], Step [4000/12500], Loss: 0.1320\n",
            "Epoch [95/100], Step [6000/12500], Loss: 0.6812\n",
            "Epoch [95/100], Step [8000/12500], Loss: 0.0001\n",
            "Epoch [95/100], Step [10000/12500], Loss: 0.8164\n",
            "Epoch [95/100], Step [12000/12500], Loss: 0.0080\n",
            "Epoch [96/100], Step [2000/12500], Loss: 0.0734\n",
            "Epoch [96/100], Step [4000/12500], Loss: 0.0045\n",
            "Epoch [96/100], Step [6000/12500], Loss: 0.4095\n",
            "Epoch [96/100], Step [8000/12500], Loss: 0.1732\n",
            "Epoch [96/100], Step [10000/12500], Loss: 0.1248\n",
            "Epoch [96/100], Step [12000/12500], Loss: 0.7466\n",
            "Epoch [97/100], Step [2000/12500], Loss: 0.0341\n",
            "Epoch [97/100], Step [4000/12500], Loss: 0.0109\n",
            "Epoch [97/100], Step [6000/12500], Loss: 0.0094\n",
            "Epoch [97/100], Step [8000/12500], Loss: 0.0820\n",
            "Epoch [97/100], Step [10000/12500], Loss: 0.1121\n",
            "Epoch [97/100], Step [12000/12500], Loss: 2.3512\n",
            "Epoch [98/100], Step [2000/12500], Loss: 0.0062\n",
            "Epoch [98/100], Step [4000/12500], Loss: 0.0024\n",
            "Epoch [98/100], Step [6000/12500], Loss: 0.0522\n",
            "Epoch [98/100], Step [8000/12500], Loss: 0.0134\n",
            "Epoch [98/100], Step [10000/12500], Loss: 0.0011\n",
            "Epoch [98/100], Step [12000/12500], Loss: 0.1544\n",
            "Epoch [99/100], Step [2000/12500], Loss: 0.0011\n",
            "Epoch [99/100], Step [4000/12500], Loss: 0.0007\n",
            "Epoch [99/100], Step [6000/12500], Loss: 0.2076\n",
            "Epoch [99/100], Step [8000/12500], Loss: 0.0227\n",
            "Epoch [99/100], Step [10000/12500], Loss: 0.5311\n",
            "Epoch [99/100], Step [12000/12500], Loss: 0.0383\n",
            "Epoch [100/100], Step [2000/12500], Loss: 0.0001\n",
            "Epoch [100/100], Step [4000/12500], Loss: 0.3954\n",
            "Epoch [100/100], Step [6000/12500], Loss: 0.0457\n",
            "Epoch [100/100], Step [8000/12500], Loss: 0.0944\n",
            "Epoch [100/100], Step [10000/12500], Loss: 0.0075\n",
            "Epoch [100/100], Step [12000/12500], Loss: 0.2519\n",
            "Accuracy of the network 60.97 %\n",
            "Accuracy of plane: 68.3%\n",
            "Accuracy of car: 71.2%\n",
            "Accuracy of bird: 50.9%\n",
            "Accuracy of cat: 43.3%\n",
            "Accuracy of deer: 55.4%\n",
            "Accuracy of dog: 48.4%\n",
            "Accuracy of frog: 68.3%\n",
            "Accuracy of horse: 65.9%\n",
            "Accuracy of ship: 69.0%\n",
            "Accuracy of truck: 69.0%\n"
          ]
        }
      ]
    }
  ]
}